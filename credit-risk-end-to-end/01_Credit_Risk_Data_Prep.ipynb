{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a52c80c4-1ea2-4d1e-b582-fac51081e76d",
   "metadata": {},
   "source": [
    "<center><img src=https://raw.githubusercontent.com/feast-dev/feast/master/docs/assets/feast_logo.png width=400/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "576a8e30-fe4c-4eda-bc56-9edd7fde3385",
   "metadata": {},
   "source": [
    "# Credit Risk Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f3fbd5a-1587-4b4e-9263-a57490657337",
   "metadata": {},
   "source": [
    "Predicting credit risk is an important task for financial institutions. If a bank can accurately determine the probability that a borrower will pay back a future loan, then they can make better decisions on loan terms and approvals. Getting credit risk right is critical to offering good financial services, and getting credit risk wrong could mean going out of business.\n",
    "\n",
    "AI models have played a central role in modern credit risk assessment systems. In this example, we develop a credit risk model to predict whether a future loan will be good or bad, given some context data (presumably supplied from the loan application). We use the modeling process to demonstrate how Feast can be used to facilitate the serving of data for training and inference use-cases.\n",
    "\n",
    "In this notebook, we prepare the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d05715f-ddb8-42de-8f0c-212dcbad9e0e",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fba29f9-db1f-4ceb-b066-5b2df2c95d33",
   "metadata": {},
   "source": [
    "*The following code assumes that you have read the example README.md file, and that you have setup an environment where the code can be run. Please make sure you have addressed the prerequisite needs.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a897b19-6f82-4631-ae51-8a23182ff267",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Python libraries\n",
    "import os\n",
    "import warnings\n",
    "import datetime as dt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets import fetch_openml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b944ed48-54b3-43fa-8373-ce788d7e71af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# suppress warning messages for example flow (don't run if you want to see warnings)\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70788c73-144f-4ecf-b370-c5669c538d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seed for reproducibility\n",
    "SEED = 142"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfb4dfd0-f583-4aa0-bd39-3ff9fbb80db0",
   "metadata": {},
   "source": [
    "### Pull the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c206dfc-d551-4002-ae63-ccbb981768fa",
   "metadata": {},
   "source": [
    "The data we will use to train the model is from the [OpenML](https://www.openml.org/) dataset [credit-g](https://www.openml.org/search?type=data&sort=runs&status=active&id=31), obtained from a 1994 German study. More details on the data can be found in the `DESC` attribute and `details` map (see below)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31a9e964-bdb3-4ae4-b2b4-64bbe0ab93a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = fetch_openml(name=\"credit-g\", version=1, parser='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58dbf7c2-f40b-4965-baac-6903a27ef622",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.DESCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53de57ec-0fb6-4b51-9c27-696b059a1847",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Original data url: \".ljust(20), data.details[\"original_data_url\"])\n",
    "print(\"Paper url: \".ljust(20), data.details[\"paper_url\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b2c2514-484e-46cb-aedc-89a301266f44",
   "metadata": {},
   "source": [
    "### High-Level Data Inspection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a76af306-caba-403d-a9cb-b5de12573075",
   "metadata": {},
   "source": [
    "Let's inspect the data to see high level details like data types and size. We also want to make sure there are no glaring issues (like a large number of null values)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20fb82c4-ed8d-42f8-b386-c7ebdc9bf786",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data.frame\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a384932a-40df-45f6-bfbc-a9cf6c708f1b",
   "metadata": {},
   "source": [
    "We see that there are 21 columns, each with 1000 non-null values. The first 20 columns are contextual fields with `Dtype` of `category` or `int64`, while the last field is actually the target variable, `class`, which we wish to predict. \n",
    "\n",
    "From the description (above), the `class` tells us whether a loan to a customer was \"good\" or \"bad\". We are anticipating that patterns in the contextual data, as well as their relationship to the class outcomes, can give insight into loan classification. In the following notebooks, we will build a loan classification model that seeks to encode these patterns and relationships in its weights, such that given a new loan application (context data), the model can predict whether the loan (if approved) will be good or bad in the future."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a451c9a3-0390-4d5a-b687-c59f52445eb1",
   "metadata": {},
   "source": [
    "### Data Preparation For Demonstrating Feast"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc4e7653-b118-44c3-ade3-f1b217b112fc",
   "metadata": {},
   "source": [
    "At this point, it's important to bring up that Feast was developed primarily to work with production data. Feast requires datasets to have entities (in our case, IDs) and timestamps, which it uses in joins. Feast can support joining data on multiple entities (like primary keys in SQL), as well as \"created\" timestamps and \"event\" timestamps. However, in this example, we'll keep things more simple.\n",
    "\n",
    "In a real loan application scenario, the application fields (in a database) would be associated with a timestamp, while the actual loan outcome (label) would be determined much later and recorded separately with a different timestamp.\n",
    "\n",
    "In order to demonstrate Feast capabilities, such as point-in-time joins, we will mock IDs and timestamps for this data. For IDs, we will use the original dataframe index values. For the timestamps, we will generate random values between \"Tue Sep 24 12:00:00 2023\" and \"Wed Oct  9 12:00:00 2023\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d6ec4f6-9410-4858-a440-45dccaa0896b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make index into \"ID\" column\n",
    "df = df.reset_index(names=[\"ID\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "055f2cb7-3abf-4d01-be60-e4c7b8ad1988",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add mock timestamps\n",
    "time_format = \"%a %b %d %H:%M:%S %Y\"\n",
    "date = dt.datetime.strptime(\"Wed Oct  9 12:00:00 2023\", time_format)\n",
    "end = int(date.timestamp())\n",
    "start = int((date - dt.timedelta(days=15)).timestamp())  # 'Tue Sep 24 12:00:00 2023'\n",
    "\n",
    "def make_tstamp(date):\n",
    "    dtime = dt.datetime.fromtimestamp(date).ctime()\n",
    "    return dtime\n",
    "    \n",
    "# (seed set for reproducibility)\n",
    "np.random.seed(SEED)\n",
    "df[\"application_timestamp\"] = pd.to_datetime([\n",
    "    make_tstamp(d) for d in np.random.randint(start, end, len(df))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7800ea9-de9a-4aab-9d77-c4276e7db5f9",
   "metadata": {},
   "source": [
    "Verify that the newly created \"ID\" and \"application_timestamp\" fields were added to the data as expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9516fc5c-7c25-4e60-acba-7400ab6bab42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check data (first few records, transposed for readability)\n",
    "df.head(3).T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72b2105a-b459-4715-aa53-6fe69fc4a210",
   "metadata": {},
   "source": [
    "We'll also generate counterpart IDs and timestamps on the label data. In a real-life scenario, the label data would come separate and later relative to the loan application data. To mimic this, let's create a labels dataset with an \"outcome_timestamp\" column with a variable lag from the application timestamp of 30 to 90 days."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e214478b-ed9b-4354-ba6f-4117813c56c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add (lagged) label timestamps (30 to 90 days)\n",
    "def lag_delta(data, seed):\n",
    "    np.random.seed(seed)\n",
    "    delta_days = np.random.randint(30, 90, len(data))\n",
    "    delta_hours = np.random.randint(0, 24, len(data))\n",
    "    delta = np.array([dt.timedelta(days=int(delta_days[i]), hours=int(delta_hours[i])) for i in range(len(data))])\n",
    "    return delta\n",
    "\n",
    "labels = df[[\"ID\", \"class\"]]\n",
    "labels[\"outcome_timestamp\"] = pd.to_datetime(df.application_timestamp + lag_delta(df, SEED))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "356a7225-db20-4c15-87a3-4a0eb3127475",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check labels\n",
    "labels.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a29f754-f758-402b-ac42-2dcfcee3b7fc",
   "metadata": {},
   "source": [
    "You can verify that the `outcome timestamp` has a difference of 30 to 90 days from the \"application_timestamp\" (above)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e720ce24-e092-4fcd-be3e-68bb18f4d2a7",
   "metadata": {},
   "source": [
    "### Save Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cae0578-8431-46c7-8d64-e52146f47d46",
   "metadata": {},
   "source": [
    "Now that we have our data prepared, let's save it to local parquet files in the `data` directory (parquet is one of the file formats supported by Feast).\n",
    "\n",
    "One more step we will add is splitting the context data column-wise and saving it in two files. This step is contrived--we don't usually split data when we don't need to--but it will allow us to demonstrate later how Feast can easily join datasets (a common need in Data Science projects)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cebef56c-1f54-4d31-a545-75d708d38579",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the data directory if it doesn't exist\n",
    "os.makedirs(\"Feature_Store/data\", exist_ok=True)\n",
    "\n",
    "# Split columns and save context data\n",
    "a_cols = [\n",
    "    'ID', 'checking_status', 'duration', 'credit_history', 'purpose',\n",
    "    'credit_amount', 'savings_status', 'employment', 'application_timestamp',\n",
    "    'installment_commitment', 'personal_status', 'other_parties',\n",
    "]\n",
    "b_cols = [\n",
    "    'ID', 'residence_since', 'property_magnitude', 'age', 'other_payment_plans',\n",
    "    'housing', 'existing_credits', 'job', 'num_dependents', 'own_telephone',\n",
    "    'foreign_worker', 'application_timestamp'\n",
    "]\n",
    "\n",
    "df[a_cols].to_parquet(\"Feature_Store/data/data_a.parquet\", engine=\"pyarrow\")\n",
    "df[b_cols].to_parquet(\"Feature_Store/data/data_b.parquet\", engine=\"pyarrow\")\n",
    "\n",
    "# Save label data\n",
    "labels.to_parquet(\"Feature_Store/data/labels.parquet\", engine=\"pyarrow\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8d5de9f-bd27-4e95-802c-b121743dd1b0",
   "metadata": {},
   "source": [
    "We have saved the following files to the `Feature_Store/data` directory: \n",
    "- `data_a.parquet` (training data, a columns)\n",
    "- `data_b.parquet` (training data, b columns)\n",
    "- `labels.parquet` (label outcomes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af6355dc-ff5b-4b3f-b0bd-3c4020ef67e8",
   "metadata": {},
   "source": [
    "With the feature data prepared, we are ready to setup and deploy the feature store. \n",
    "\n",
    "Continue with the [02_Deploying_the_Feature_Store.ipynb](02_Deploying_the_Feature_Store.ipynb) notebook."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bin",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
